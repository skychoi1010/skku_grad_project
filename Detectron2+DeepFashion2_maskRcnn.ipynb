{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Detectron2+DeepFashion2.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyOgJkN6oXOMW/A28ieYr9LS"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# **Install Detectron2**"],"metadata":{"id":"_ZnhHkGpqbhs"}},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Kt7y93ZVqUyo","executionInfo":{"status":"ok","timestamp":1647670481049,"user_tz":-540,"elapsed":119779,"user":{"displayName":"HANL CHOI","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00251342925066352818"}},"outputId":"c7c149aa-43fb-40b0-9244-76fdff42b960"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in links: https://download.pytorch.org/whl/cu101/torch_stable.html\n","Collecting torch==1.5\n","  Downloading https://download.pytorch.org/whl/cu101/torch-1.5.0%2Bcu101-cp37-cp37m-linux_x86_64.whl (703.8 MB)\n","\u001b[K     |████████████████████████████████| 703.8 MB 24 kB/s \n","\u001b[?25hCollecting torchvision==0.6\n","  Downloading https://download.pytorch.org/whl/cu101/torchvision-0.6.0%2Bcu101-cp37-cp37m-linux_x86_64.whl (6.6 MB)\n","\u001b[K     |████████████████████████████████| 6.6 MB 5.2 MB/s \n","\u001b[?25hRequirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from torch==1.5) (0.16.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch==1.5) (1.21.5)\n","Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from torchvision==0.6) (7.1.2)\n","Installing collected packages: torch, torchvision\n","  Attempting uninstall: torch\n","    Found existing installation: torch 1.10.0+cu111\n","    Uninstalling torch-1.10.0+cu111:\n","      Successfully uninstalled torch-1.10.0+cu111\n","  Attempting uninstall: torchvision\n","    Found existing installation: torchvision 0.11.1+cu111\n","    Uninstalling torchvision-0.11.1+cu111:\n","      Successfully uninstalled torchvision-0.11.1+cu111\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","torchtext 0.11.0 requires torch==1.10.0, but you have torch 1.5.0+cu101 which is incompatible.\n","torchaudio 0.10.0+cu111 requires torch==1.10.0, but you have torch 1.5.0+cu101 which is incompatible.\u001b[0m\n","Successfully installed torch-1.5.0+cu101 torchvision-0.6.0+cu101\n","Requirement already satisfied: cython in /usr/local/lib/python3.7/dist-packages (0.29.28)\n","Collecting pyyaml==5.1\n","  Downloading PyYAML-5.1.tar.gz (274 kB)\n","\u001b[K     |████████████████████████████████| 274 kB 5.3 MB/s \n","\u001b[?25hBuilding wheels for collected packages: pyyaml\n","  Building wheel for pyyaml (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pyyaml: filename=PyYAML-5.1-cp37-cp37m-linux_x86_64.whl size=44092 sha256=ae3a5c6436793cabe50e4c7e87011dce71a72cd170479db3c7bba835897253dc\n","  Stored in directory: /root/.cache/pip/wheels/77/f5/10/d00a2bd30928b972790053b5de0c703ca87324f3fead0f2fd9\n","Successfully built pyyaml\n","Installing collected packages: pyyaml\n","  Attempting uninstall: pyyaml\n","    Found existing installation: PyYAML 3.13\n","    Uninstalling PyYAML-3.13:\n","      Successfully uninstalled PyYAML-3.13\n","Successfully installed pyyaml-5.1\n","Collecting git+https://github.com/cocodataset/cocoapi.git#subdirectory=PythonAPI\n","  Cloning https://github.com/cocodataset/cocoapi.git to /tmp/pip-req-build-f4a704be\n","  Running command git clone -q https://github.com/cocodataset/cocoapi.git /tmp/pip-req-build-f4a704be\n","Requirement already satisfied: setuptools>=18.0 in /usr/local/lib/python3.7/dist-packages (from pycocotools==2.0) (57.4.0)\n","Requirement already satisfied: cython>=0.27.3 in /usr/local/lib/python3.7/dist-packages (from pycocotools==2.0) (0.29.28)\n","Requirement already satisfied: matplotlib>=2.1.0 in /usr/local/lib/python3.7/dist-packages (from pycocotools==2.0) (3.2.2)\n","Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.1.0->pycocotools==2.0) (1.21.5)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.1.0->pycocotools==2.0) (2.8.2)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.1.0->pycocotools==2.0) (3.0.7)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.1.0->pycocotools==2.0) (1.3.2)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.1.0->pycocotools==2.0) (0.11.0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib>=2.1.0->pycocotools==2.0) (1.15.0)\n","Building wheels for collected packages: pycocotools\n","  Building wheel for pycocotools (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pycocotools: filename=pycocotools-2.0-cp37-cp37m-linux_x86_64.whl size=264357 sha256=b40efbf82112328a479792b07a4cbe55fe592f44494d6d3490c5cc8211198e5c\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-0nb_dtq5/wheels/e2/6b/1d/344ac773c7495ea0b85eb228bc66daec7400a143a92d36b7b1\n","Successfully built pycocotools\n","Installing collected packages: pycocotools\n","  Attempting uninstall: pycocotools\n","    Found existing installation: pycocotools 2.0.4\n","    Uninstalling pycocotools-2.0.4:\n","      Successfully uninstalled pycocotools-2.0.4\n","Successfully installed pycocotools-2.0\n","1.5.0+cu101 True\n","gcc (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0\n","Copyright (C) 2017 Free Software Foundation, Inc.\n","This is free software; see the source for copying conditions.  There is NO\n","warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\n","\n","Looking in links: https://dl.fbaipublicfiles.com/detectron2/wheels/cu101/index.html\n","Collecting detectron2==0.1.3\n","  Downloading https://dl.fbaipublicfiles.com/detectron2/wheels/cu101/torch1.5/detectron2-0.1.3%2Bcu101-cp37-cp37m-linux_x86_64.whl (6.2 MB)\n","\u001b[K     |████████████████████████████████| 6.2 MB 890 kB/s \n","\u001b[?25hRequirement already satisfied: tabulate in /usr/local/lib/python3.7/dist-packages (from detectron2==0.1.3) (0.8.9)\n","Collecting mock\n","  Downloading mock-4.0.3-py3-none-any.whl (28 kB)\n","Requirement already satisfied: cloudpickle in /usr/local/lib/python3.7/dist-packages (from detectron2==0.1.3) (1.3.0)\n","Requirement already satisfied: tensorboard in /usr/local/lib/python3.7/dist-packages (from detectron2==0.1.3) (2.8.0)\n","Requirement already satisfied: pydot in /usr/local/lib/python3.7/dist-packages (from detectron2==0.1.3) (1.3.0)\n","Requirement already satisfied: termcolor>=1.1 in /usr/local/lib/python3.7/dist-packages (from detectron2==0.1.3) (1.1.0)\n","Collecting fvcore>=0.1.1\n","  Downloading fvcore-0.1.5.post20220305.tar.gz (50 kB)\n","\u001b[K     |████████████████████████████████| 50 kB 4.8 MB/s \n","\u001b[?25hRequirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from detectron2==0.1.3) (0.16.0)\n","Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from detectron2==0.1.3) (7.1.2)\n","Collecting yacs>=0.1.6\n","  Downloading yacs-0.1.8-py3-none-any.whl (14 kB)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from detectron2==0.1.3) (3.2.2)\n","Requirement already satisfied: tqdm>4.29.0 in /usr/local/lib/python3.7/dist-packages (from detectron2==0.1.3) (4.63.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from fvcore>=0.1.1->detectron2==0.1.3) (1.21.5)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from fvcore>=0.1.1->detectron2==0.1.3) (5.1)\n","Collecting iopath>=0.1.7\n","  Downloading iopath-0.1.9-py3-none-any.whl (27 kB)\n","Collecting portalocker\n","  Downloading portalocker-2.4.0-py2.py3-none-any.whl (16 kB)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->detectron2==0.1.3) (1.3.2)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->detectron2==0.1.3) (0.11.0)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->detectron2==0.1.3) (3.0.7)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->detectron2==0.1.3) (2.8.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib->detectron2==0.1.3) (1.15.0)\n","Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2==0.1.3) (1.44.0)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2==0.1.3) (1.8.1)\n","Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2==0.1.3) (3.17.3)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2==0.1.3) (2.23.0)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2==0.1.3) (3.3.6)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2==0.1.3) (0.4.6)\n","Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2==0.1.3) (57.4.0)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2==0.1.3) (1.0.1)\n","Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2==0.1.3) (1.0.0)\n","Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2==0.1.3) (0.37.1)\n","Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2==0.1.3) (0.6.1)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2==0.1.3) (1.35.0)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard->detectron2==0.1.3) (4.8)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard->detectron2==0.1.3) (0.2.8)\n","Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard->detectron2==0.1.3) (4.2.4)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard->detectron2==0.1.3) (1.3.1)\n","Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard->detectron2==0.1.3) (4.11.2)\n","Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard->detectron2==0.1.3) (3.10.0.2)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard->detectron2==0.1.3) (3.7.0)\n","Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard->detectron2==0.1.3) (0.4.8)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard->detectron2==0.1.3) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard->detectron2==0.1.3) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard->detectron2==0.1.3) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard->detectron2==0.1.3) (2021.10.8)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard->detectron2==0.1.3) (3.2.0)\n","Building wheels for collected packages: fvcore\n","  Building wheel for fvcore (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for fvcore: filename=fvcore-0.1.5.post20220305-py3-none-any.whl size=61214 sha256=0fc0bcfe36e36820f99b534b283ecda474f2684aae1ced0f91e1716cfeabab72\n","  Stored in directory: /root/.cache/pip/wheels/b5/b7/6e/43b1693d06fac3633af48db68557513b0a37ab38b0a8b798f9\n","Successfully built fvcore\n","Installing collected packages: portalocker, yacs, iopath, mock, fvcore, detectron2\n","Successfully installed detectron2-0.1.3+cu101 fvcore-0.1.5.post20220305 iopath-0.1.9 mock-4.0.3 portalocker-2.4.0 yacs-0.1.8\n"]}],"source":["# install dependencies: (use cu101 because colab has CUDA 10.1)\n","!pip install -U torch==1.5 torchvision==0.6 -f https://download.pytorch.org/whl/cu101/torch_stable.html \n","!pip install cython pyyaml==5.1\n","!pip install -U 'git+https://github.com/cocodataset/cocoapi.git#subdirectory=PythonAPI'\n","import torch, torchvision\n","print(torch.__version__, torch.cuda.is_available())\n","!gcc --version\n","\n","!pip install detectron2==0.1.3 -f https://dl.fbaipublicfiles.com/detectron2/wheels/cu101/index.html"]},{"cell_type":"markdown","source":["# **Download Dataset: DeepFashion2**"],"metadata":{"id":"JO-WGmVcqkYl"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5IRqmzZSo9lM","executionInfo":{"status":"ok","timestamp":1647673096429,"user_tz":-540,"elapsed":107919,"user":{"displayName":"HANL CHOI","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00251342925066352818"}},"outputId":"ad84f426-f610-4a6f-8f50-bdfa2d9f9860"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["#!mkdir ./drive/MyDrive/detectron/data/DeepFashion2/\n","#!gdown --id 1-e6J3rm1hXITaLQRtKSzgMd5bwm0J6wu -O ./drive/MyDrive/detectron/data/DeepFashion2/validation.zip"],"metadata":{"id":"r20K_yhRqjoH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#!unzip -P \"password\" ./drive/MyDrive/detectron/data/DeepFashion2/eepFashion2/validation.zip -d ./drive/MyDrive/detectron/data/DeepFashion2/\n","#### done ####\n","#!unzip -P \"2019Deepfashion2**\" ./drive/MyDrive/detectron/data/DeepFashion2/validation.zip -d ./drive/MyDrive/detectron/data/DeepFashion2/"],"metadata":{"id":"A1zcDelsqu-D"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#이미지와 annotation file의 개수 확인\n","!ls ./drive/MyDrive/detectron/data/DeepFashion2/validation/image | wc -l\n","!ls ./drive/MyDrive/detectron/data/DeepFashion2/validation/annos | wc -l"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":408},"id":"f-2oBtskqv-9","executionInfo":{"status":"error","timestamp":1647616811894,"user_tz":-540,"elapsed":193447,"user":{"displayName":"HANL CHOI","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00251342925066352818"}},"outputId":"d1e9d8ea-cc19-4edc-e272-16ec3d64c2cb"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["ls: cannot open directory './drive/MyDrive/detectron/data/DeepFashion2/validation/image': Input/output error\n","0\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-3-868101a8e7ff>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#이미지와 annotation file의 개수 확인\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ls ./drive/MyDrive/detectron/data/DeepFashion2/validation/image | wc -l'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ls ./drive/MyDrive/detectron/data/DeepFashion2/validation/annos | wc -l'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/google/colab/_shell.py\u001b[0m in \u001b[0;36msystem\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    100\u001b[0m       \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'also_return_output'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_system_commands\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_system_compat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint:disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mpip_warn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/google/colab/_system_commands.py\u001b[0m in \u001b[0;36m_system_compat\u001b[0;34m(shell, cmd, also_return_output)\u001b[0m\n\u001b[1;32m    445\u001b[0m   \u001b[0;31m# stack.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    446\u001b[0m   result = _run_command(\n\u001b[0;32m--> 447\u001b[0;31m       shell.var_expand(cmd, depth=2), clear_streamed_output=False)\n\u001b[0m\u001b[1;32m    448\u001b[0m   \u001b[0mshell\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_ns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'_exit_code'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    449\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_INTERRUPTED_SIGNALS\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/google/colab/_system_commands.py\u001b[0m in \u001b[0;36m_run_command\u001b[0;34m(cmd, clear_streamed_output)\u001b[0m\n\u001b[1;32m    197\u001b[0m       \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchild_pty\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0m_monitor_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparent_pty\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoll\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mupdate_stdin_widget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m   \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m     \u001b[0mepoll\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/google/colab/_system_commands.py\u001b[0m in \u001b[0;36m_monitor_process\u001b[0;34m(parent_pty, epoll, p, cmd, update_stdin_widget)\u001b[0m\n\u001b[1;32m    227\u001b[0m   \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 229\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_poll_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparent_pty\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoll\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    230\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/google/colab/_system_commands.py\u001b[0m in \u001b[0;36m_poll_process\u001b[0;34m(parent_pty, epoll, p, cmd, decoder, state)\u001b[0m\n\u001b[1;32m    274\u001b[0m   \u001b[0moutput_available\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 276\u001b[0;31m   \u001b[0mevents\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mepoll\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    277\u001b[0m   \u001b[0minput_events\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mevents\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"markdown","source":["# **Convert to COCO format**"],"metadata":{"id":"AV5x0BGHq3vF"}},{"cell_type":"code","source":["from PIL import Image\n","import numpy as np\n","import json\n","\n","dataset = {\n","    \"info\": {},\n","    \"licenses\": [],\n","    \"images\": [],\n","    \"annotations\": [],\n","    \"categories\": []\n","}\n","\n","lst_name = ['short_sleeved_shirt', 'long_sleeved_shirt', 'short_sleeved_outwear', 'long_sleeved_outwear',\n","            'vest', 'sling', 'shorts', 'trousers', 'skirt', 'short_sleeved_dress',\n","            'long_sleeved_dress', 'vest_dress', 'sling_dress']\n","\n","for idx, e  in enumerate(lst_name):\n","    dataset['categories'].append({\n","        'id': idx + 1,\n","        'name': e,\n","        'supercategory': \"clothes\",\n","        'keypoints': ['%i' % (i) for i in range(1, 295)],\n","        'skeleton': []\n","    })\n","\n","num_images = 32153 #191961 \n","sub_index = 0  # the index of ground truth instance\n","for num in range(1, num_images + 1):\n","    json_name = './drive/MyDrive/detectron/data/DeepFashion2/validation/annos/' + str(num).zfill(6) + '.json'\n","    image_name = './drive/MyDrive/detectron/data/DeepFashion2/validation/image/' + str(num).zfill(6) + '.jpg'\n","\n","    if (num >= 0):\n","        imag = Image.open(image_name)\n","        width, height = imag.size\n","        with open(json_name, 'r') as f:\n","            temp = json.loads(f.read())\n","            pair_id = temp['pair_id']\n","\n","            dataset['images'].append({\n","                'coco_url': '',\n","                'date_captured': '',\n","                'file_name': str(num).zfill(6) + '.jpg',\n","                'flickr_url': '',\n","                'id': num,\n","                'license': 0,\n","                'width': width,\n","                'height': height\n","            })\n","            for i in temp:\n","                if i == 'source' or i == 'pair_id':\n","                    continue\n","                else:\n","                    points = np.zeros(294 * 3)\n","                    sub_index = sub_index + 1\n","                    box = temp[i]['bounding_box']\n","                    w = box[2] - box[0]\n","                    h = box[3] - box[1]\n","                    x_1 = box[0]\n","                    y_1 = box[1]\n","                    bbox = [x_1, y_1, w, h]\n","                    cat = temp[i]['category_id']\n","                    style = temp[i]['style']\n","                    seg = temp[i]['segmentation']\n","                    landmarks = temp[i]['landmarks']\n","\n","                    points_x = landmarks[0::3]\n","                    points_y = landmarks[1::3]\n","                    points_v = landmarks[2::3]\n","                    points_x = np.array(points_x)\n","                    points_y = np.array(points_y)\n","                    points_v = np.array(points_v)\n","                    case = [0, 25, 58, 89, 128, 143, 158, 168, 182, 190, 219, 256, 275, 294]\n","                    idx_i, idx_j = case[cat - 1], case[cat]\n","\n","                    for n in range(idx_i, idx_j):\n","                        points[3 * n] = points_x[n - idx_i]\n","                        points[3 * n + 1] = points_y[n - idx_i]\n","                        points[3 * n + 2] = points_v[n - idx_i]\n","\n","                    num_points = len(np.where(points_v > 0)[0])\n","\n","                    dataset['annotations'].append({\n","                        'area': w * h,\n","                        'bbox': bbox,\n","                        'category_id': cat,\n","                        'id': sub_index,\n","                        'pair_id': pair_id,\n","                        'image_id': num,\n","                        'iscrowd': 0,\n","                        'style': style,\n","                        'num_keypoints': num_points,\n","                        'keypoints': points.tolist(),\n","                        'segmentation': seg,\n","                    })\n","\n","json_name = './drive/MyDrive/detectron/data/DeepFashion2/deepfashion2_validation.json'\n","with open(json_name, 'w') as f:\n","    json.dump(dataset, f)"],"metadata":{"id":"0f1i9cGMq6jC"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **Package Imports**"],"metadata":{"id":"EQtFw5oBrDCQ"}},{"cell_type":"code","source":["# Setup detectron2 logger\n","import detectron2\n","from detectron2.utils.logger import setup_logger\n","setup_logger()\n","\n","# import some common libraries\n","import os\n","import numpy as np\n","import cv2\n","import random\n","from google.colab.patches import cv2_imshow\n","\n","# import some common detectron2 utilities\n","from detectron2 import model_zoo\n","from detectron2.engine import DefaultPredictor\n","from detectron2.engine import DefaultTrainer\n","from detectron2.config import get_cfg\n","from detectron2.utils.visualizer import Visualizer\n","from detectron2.data import MetadataCatalog"],"metadata":{"id":"xR1VB8QirFzj"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **Register Dataset**"],"metadata":{"id":"jNOByP0OrIke"}},{"cell_type":"code","source":["from detectron2.data.datasets import register_coco_instances\n","#register_coco_instances(\"deepfashion_train\", {}, \"./drive/MyDrive/detectron/data/DeepFashion2/deepfashion2_train.json\", \"./drive/MyDrive/detectron/data/DeepFashion2/train/image\")\n","register_coco_instances(\"deepfashion_validation\", {}, './drive/MyDrive/detectron/data/DeepFashion2/deepfashion2_validation.json', \"./drive/MyDrive/detectron/data/DeepFashion2/validation/image\")"],"metadata":{"id":"7CyOmW0brKVm"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **Create Config for Training**"],"metadata":{"id":"COhyJn6RrRFH"}},{"cell_type":"code","source":["cfg = get_cfg()\n","\n","cfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\"))\n","cfg.DATASETS.TRAIN = (\"deepfashion_validation\",)\n","cfg.DATASETS.TEST = ()\n","cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\")  # Let training initialize from model zoo\n","\n","cfg.SOLVER.IMS_PER_BATCH = 4\n","cfg.SOLVER.BASE_LR = 0.001\n","cfg.SOLVER.WARMUP_ITERS = 1000\n","cfg.SOLVER.MAX_ITER = 1500\n","cfg.SOLVER.STEPS = (1000, 1500)\n","cfg.SOLVER.GAMMA = 0.05\n","cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 64\n","cfg.MODEL.ROI_HEADS.NUM_CLASSES = 13\n","\n","cfg.TEST.EVAL_PERIOD = 500"],"metadata":{"id":"s-VAGnz_rUDT"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **Training**"],"metadata":{"id":"MHZvRD-QrX6c"}},{"cell_type":"markdown","source":["Detectron2 DefaultTrainer module"],"metadata":{"id":"WL2jpAOOrf0q"}},{"cell_type":"code","source":["os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n","trainer = DefaultTrainer(cfg) \n","trainer.resume_or_load(resume=False)\n","trainer.train()"],"metadata":{"id":"UMMJ-jFRrbfI"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Training performance on Tensorboard"],"metadata":{"id":"0lHdGM7urlxL"}},{"cell_type":"code","source":["# Look at training curves in tensorboard:\n","%load_ext tensorboard\n","%tensorboard --logdir output"],"metadata":{"id":"a0sLA4OarsZD"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **Make Predictions**"],"metadata":{"id":"1RRolT1JrvcE"}},{"cell_type":"code","source":["# validation set 사용 시 threshold/iteration 횟수 적게\n","cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\")\n","cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.55   # set the testing threshold for this model\n","cfg.DATASETS.TEST = (\"deepfashion__validation\", )\n","predictor = DefaultPredictor(cfg)"],"metadata":{"id":"hJHzv034r2ct"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["테스트용 외부 이미지"],"metadata":{"id":"MNUHVquEsEjA"}},{"cell_type":"code","source":["!wget https://img-lcwaikiki.mncdn.com/mnresize/1024/-//productimages/20201/1/3945185/l_20201-0sg016z8-cs8_a.jpg -O /content/example.jpg"],"metadata":{"id":"JLHMJQ8OsGNK"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["predictor에 데이터 넣고 시각화"],"metadata":{"id":"tI3v_wipsIRd"}},{"cell_type":"code","source":["from detectron2.utils.visualizer import ColorMode\n","im = cv2.imread(\"/content/example.jpg\")\n","outputs = predictor(im)\n","# We can use `Visualizer` to draw the predictions on the image.\n","v = Visualizer(im[:, :, ::-1], MetadataCatalog.get(cfg.DATASETS.TRAIN[0]), scale=1.2, instance_mode=ColorMode.IMAGE_BW)\n","v = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n","cv2_imshow(v.get_image()[:, :, ::-1])"],"metadata":{"id":"_0rYfy0lsL-u"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["im = cv2.imread(\"/content/example.jpg\")\n","outputs = predictor(im)\n","# We can use `Visualizer` to draw the predictions on the image.\n","meta =MetadataCatalog.get(cfg.DATASETS.TRAIN[0])\n","meta.thing_colors=[(102, 255, 102), (102, 255, 255), (102, 102, 255)]\n","v = Visualizer(im[:, :, ::-1], meta, scale=1.2, instance_mode=ColorMode.IMAGE_BW)\n","out = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n","cv2_imshow(out.get_image()[:, :, ::-1])"],"metadata":{"id":"X7nCmX5o1F3N"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["im = cv2.imread(\"/content/pic2.jpg\")\n","outputs = predictor(im)\n","# We can use `Visualizer` to draw the predictions on the image.\n","v = Visualizer(im[:, :, ::-1], MetadataCatalog.get(cfg.DATASETS.TRAIN[0]), scale=1.2)\n","v = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n","cv2_imshow(v.get_image()[:, :, ::-1])"],"metadata":{"id":"3IuPhs_Q1hu8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["im = cv2.imread(\"/content/pic3.jpg\")\n","outputs = predictor(im)\n","# We can use `Visualizer` to draw the predictions on the image.\n","v = Visualizer(im[:, :, ::-1], MetadataCatalog.get(cfg.DATASETS.TRAIN[0]), scale=1.2)\n","v = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n","cv2_imshow(v.get_image()[:, :, ::-1])"],"metadata":{"id":"KalsK0O22d2X"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["im = cv2.imread(\"/content/pic4.jpg\")\n","outputs = predictor(im)\n","# We can use `Visualizer` to draw the predictions on the image.\n","v = Visualizer(im[:, :, ::-1], MetadataCatalog.get(cfg.DATASETS.TRAIN[0]), scale=1.2)\n","v = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n","cv2_imshow(v.get_image()[:, :, ::-1])"],"metadata":{"id":"FcJrdkPu2jza"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["im = cv2.imread(\"/content/pic5.jpg\")\n","outputs = predictor(im)\n","# We can use `Visualizer` to draw the predictions on the image.\n","v = Visualizer(im[:, :, ::-1], MetadataCatalog.get(cfg.DATASETS.TRAIN[0]), scale=1.2)\n","v = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n","cv2_imshow(v.get_image()[:, :, ::-1])"],"metadata":{"id":"cajUemfo2mBR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["im = cv2.imread(\"/content/pic6.jpg\")\n","outputs = predictor(im)\n","# We can use `Visualizer` to draw the predictions on the image.\n","v = Visualizer(im[:, :, ::-1], MetadataCatalog.get(cfg.DATASETS.TRAIN[0]), scale=1.2)\n","v = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n","cv2_imshow(v.get_image()[:, :, ::-1])"],"metadata":{"id":"kqJcO25c2nxL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["im = cv2.imread(\"/content/pic7.jpg\")\n","outputs = predictor(im)\n","# We can use `Visualizer` to draw the predictions on the image.\n","v = Visualizer(im[:, :, ::-1], MetadataCatalog.get(cfg.DATASETS.TRAIN[0]), scale=1.2)\n","v = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n","cv2_imshow(v.get_image()[:, :, ::-1])"],"metadata":{"id":"w8enNdQH2ptf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["im = cv2.imread(\"/content/pic8.jpg\")\n","outputs = predictor(im)\n","# We can use `Visualizer` to draw the predictions on the image.\n","v = Visualizer(im[:, :, ::-1], MetadataCatalog.get(cfg.DATASETS.TRAIN[0]), scale=1.2)\n","v = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n","cv2_imshow(v.get_image()[:, :, ::-1])"],"metadata":{"id":"MNpO1kCB2vdb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["im = cv2.imread(\"/content/pic9.jpg\")\n","outputs = predictor(im)\n","# We can use `Visualizer` to draw the predictions on the image.\n","v = Visualizer(im[:, :, ::-1], MetadataCatalog.get(cfg.DATASETS.TRAIN[0]), scale=1.2)\n","v = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n","cv2_imshow(v.get_image()[:, :, ::-1])"],"metadata":{"id":"WjTtsijq2xjX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["im = cv2.imread(\"/content/pic10.jpg\")\n","outputs = predictor(im)\n","# We can use `Visualizer` to draw the predictions on the image.\n","v = Visualizer(im[:, :, ::-1], MetadataCatalog.get(cfg.DATASETS.TRAIN[0]), scale=1.2)\n","v = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n","cv2_imshow(v.get_image()[:, :, ::-1])"],"metadata":{"id":"YYSXNn732z5G"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["im = cv2.imread(\"/content/pic11.jpg\")\n","outputs = predictor(im)\n","# We can use `Visualizer` to draw the predictions on the image.\n","v = Visualizer(im[:, :, ::-1], MetadataCatalog.get(cfg.DATASETS.TRAIN[0]), scale=1.2)\n","v = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n","cv2_imshow(v.get_image()[:, :, ::-1])"],"metadata":{"id":"vnYnXmv-23WA"},"execution_count":null,"outputs":[]}]}